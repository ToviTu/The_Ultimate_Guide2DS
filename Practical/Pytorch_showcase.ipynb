{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Function Showcase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as tor\n",
    "import numpy as np\n",
    "import inspect"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor\n",
    "\n",
    "Definition: Tensor is a multi-dimentional array of numerical values, denoted as $k^{th}\\ order\\ tensor$. By default, new tensors are stored in memory for CPU-based computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([10])\n",
      "tensor([[0., 1., 2., 3., 4.],\n",
      "        [5., 6., 7., 8., 9.]], dtype=torch.float64)\n",
      "tensor([[0., 1., 2., 3., 4.],\n",
      "        [5., 6., 7., 8., 9.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "\n",
    "# Populate a tensor representing range\n",
    "x = tor.arange(10, dtype=tor.float64)\n",
    "\n",
    "# Get #elements\n",
    "print(x.numel())\n",
    "\n",
    "# Get shape\n",
    "print(x.shape)\n",
    "\n",
    "# Reshape\n",
    "print(x.reshape(2,5))\n",
    "\n",
    "# Reshape with dimension inference\n",
    "print(x.reshape(2, -1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing & Computation\n",
    "- Similar to Numpy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Handeling\n",
    "Machine learning compuation tend to be memory heavy. By defualt, reusing the same variable name cause extra memory allocation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m before \u001b[39m=\u001b[39m \u001b[39mid\u001b[39m(X)\n\u001b[0;32m      5\u001b[0m X \u001b[39m=\u001b[39m X\u001b[39m+\u001b[39mY\n\u001b[1;32m----> 6\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mid\u001b[39m(X) \u001b[39m==\u001b[39m before\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X = tor.ones(10)\n",
    "Y = tor.zeros((2,1))\n",
    "\n",
    "before = id(X)\n",
    "X = X+Y\n",
    "assert id(X) == before"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution: in-place assignmnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before = id(X)\n",
    "X[:] = X+Y # or X += Y\n",
    "assert before == id(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion to Other Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to numpy array\n",
    "X.numpy()\n",
    "\n",
    "# Convert from numpy array\n",
    "tor.from_numpy(np.zeros(10))\n",
    "\n",
    "# Convert to Python scalar\n",
    "X[0,0].item()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto Differentiation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w gradient: tensor([18.]), b gradient tensor([18.])\n"
     ]
    }
   ],
   "source": [
    "X = tor.ones((3,1))\n",
    "Y = tor.zeros((3,1))\n",
    "\n",
    "w = tor.tensor([1.], requires_grad=True)\n",
    "b = tor.tensor([2.], requires_grad=True)\n",
    "\n",
    "loss = tor.norm(X@w.reshape(-1,1)+b-Y) ** 2\n",
    "loss.backward()\n",
    "print(f\"w gradient: {w.grad}, b gradient {b.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(18., grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2 * X.T @ (X@w+b-Y)).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training NN in Jupyter Notebook: An OOP Approach\n",
    "Code implementation in Python can be complex and overtly long. By convention, a NN project code base is divided into **3 modules**: `Module` class contains models, losses and optimization methods; `Data-Module` contains data loaders for training and validation; the former two classes are combined into the `Trainer` module to train on different platforms."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Attribute Insertion\n",
    "- Allows afterwards method definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My a is 1\n"
     ]
    }
   ],
   "source": [
    "def add_to_class(Class):\n",
    "    def wrapper(obj):\n",
    "        setattr(Class, obj.__name__, obj)\n",
    "    return wrapper\n",
    "\n",
    "class A:\n",
    "    def __init__(self):\n",
    "        self.a = 1\n",
    "\n",
    "a = A()\n",
    "\n",
    "@add_to_class(A)\n",
    "def say_a(self): print(f'My a is {self.a}')\n",
    "\n",
    "a.say_a()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Auto-saving\n",
    "-  Save all __init__ parameter as class attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperPrameters:\n",
    "    def save_hyperparameters(self, ignore=[]):\n",
    "        '''\n",
    "        This function saves the arguments of the last frame as the attributes of this instance\n",
    "        '''\n",
    "        frame = inspect.currentframe().f_back # access the frame of last function call\n",
    "        _, _, _, local_vars = inspect.getargvalues(frame)\n",
    "        for k, v in local_vars.items():\n",
    "            if k not in ignore: setattr(self, k, v)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "class A(HyperPrameters):\n",
    "    def __init__(self, a: int):\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "a = A(10)\n",
    "print(a.a)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progress Board\n",
    "- Diaplay a live animation showing training progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressBoard(HyperPrameters):\n",
    "    def __init__(self, xlabel=None, ylabel=None, xlim=None, ylim=None, xscale='linear', yscale='linear'):\n",
    "        self.save_hyperparameters()\n",
    "    def draw(self, x, y, label, every_n=1):\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Module Class\n",
    "The `module` class is thte base class of all models. Three methods need to be defined at a minimum:\n",
    "- `__init__` method stores the learnable parameters\n",
    "- `training_step` method accetps a data batch to return the loss value\n",
    "- `configure_optimizers` method returns the optimization method(s) used to update the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Module(nn.Module, HyperPrameters):\n",
    "    def __init__(self, plot_train_per_epoch=2, plot_vlaid_per_epoch=1):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.board = ProgressBoard()\n",
    "    \n",
    "    def loss(self, y_hat, y):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def forward(self, X):\n",
    "        assert hasattr(self, 'net')\n",
    "        return self.net(X)\n",
    "        \n",
    "    def training_step(self, batch):\n",
    "        l = self.loss(self(*batch[:-1]), batch[-1])\n",
    "        self.plot('loss', l, train=True)\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        l = self.loss(self(*batch[:-1], batch[-1]))\n",
    "        self.plot('loss', l, train=False)\n",
    "    \n",
    "    def configure_optimizer(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "The `DataModule` class is the base class for data. The `__init__` method prepares the data, including downloading and preprocessing. It serves as an interface between trainer and dataload, a Python generator that yields data batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(HyperPrameters):\n",
    "    def __init__(self, root='./data', num_workers=4):\n",
    "        self.save_hyperparameters()\n",
    "    \n",
    "    def get_dataloader(self, train):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.get_dataloader(train=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return self.get_dataloader(train=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer Class\n",
    "The `Trainer` class trains the network in the `Module` class with the data specified in `DataModule`. The `key` method accepts an instance of `Module` class and an instance of `DataModule` class. It iterates over the entire dataset max_epochs times to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(HyperPrameters):\n",
    "    def __init__(self, max_epochs: int, num_gpus=0, gradient_clip_val=0):\n",
    "        self.save_hyperparameters()\n",
    "        assert num_gpus == 0\n",
    "    \n",
    "    def prepare_data(self, data: DataModule):\n",
    "        self.train_dataloader = data.train_dataloader()\n",
    "        self.val_dataloader = data.val_dataloader()\n",
    "        self.num_train_batches = len(self.train_dataloader)\n",
    "        self.num_val_batches = len(self.val_dataloader if self.val_dataloader is not None else 0)\n",
    "\n",
    "    def prepare_model(self, model: Module):\n",
    "        model.trainer = self,\n",
    "        model.board.xlim = [0, self.max_epochs]\n",
    "        self.model = model\n",
    "    \n",
    "    def fit(self, model: Module, data: DataModule):\n",
    "        self.prepare_data(data)\n",
    "        self.prepare_model(model)\n",
    "        self.optim = model.configure_optimizers()\n",
    "        self.epoch = 0\n",
    "        self.train_batch_idx = 0\n",
    "        self.val_batch_idx = 0\n",
    "        for self.epoch in range(self.max_epochs):\n",
    "            self.fit_epoch()\n",
    "    \n",
    "    def fit_epoch(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The codes above are saved in the \"dl\" module for modular design of the network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
