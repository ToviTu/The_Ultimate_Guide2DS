{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "Neural networks on image processing tasks are not realisitic due to the 2D representation of digital image and the massive amount of neurons/weights in a fully connected network. Also, the structual knowledge has not been taken advantage of by the conventional MLP, which treats pixels separately. **CNN** prorvides a concise way to learn a relatively computationally inexpensive representation of an image and incorporates the interatcion between adjacent pixels, turning the image classification task into a linear-solvable problem. CNN layer is the earliest layer of a network and should follow 3 principals.\n",
    "1. *Translation Invariance*: the layer should respond similarly to the same patch of pixels (features) regardless of the location.\n",
    "2. *Locality*: the layer should focus on local regions not regarding remote patches.\n",
    "3. Deeper layer should capture features across long-range. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Derivation\n",
    "Let $X\\in R^2$ be a 2D image and $H\\in2$ be the representation matrix of the same shape. By tensor convention, $[X]_{i,j}$ and $[H]_{i,j}$ denote the pixel at location (i,j). In a fully connected network, the relationship between 2 matrices can be expressed as \n",
    "$$\n",
    "[H]_{i,j} = [U]_{i,j} + \\sum_a\\sum_b[V]_{i,j,a,b}[X]_{i+a,j+b}\n",
    "$$\n",
    "where $U$ is the bias matrix and V is a 4D tensor. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translation Invariance\n",
    "\n",
    "Since the layer should not vary by the location (i, j), we should have $[V]_{i,j,a,b}=[V]_{a,b}$ and same for $U$.\n",
    "$$\n",
    "[H]_{i,j} = u + \\sum_a\\sum_b[V]_{a,b}[X]_{i+a,j+b}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locality\n",
    "\n",
    "The layer shoud disregard features far away from (i,j). For some $\\Delta\\in\\mathbb{R}$, let $[V]_{a,b}=0$ for $|a|,|b|>\\Delta$.\n",
    "$$\n",
    "[H]_{i,j} = u + \\sum_{a=-\\Delta}^\\Delta\\sum_{b=-\\Delta}^\\Delta[V]_{a,b}[X]_{i+a,j+b}\n",
    "$$\n",
    "where $\\Delta$ is typically smaller than 10 in image processing context.\n",
    "\n",
    "This is called a **convolutional layer** and $V$ is the **convolutional kernel**. After transformation, we introduces translation invariance and inductive bias into the training data. Such assumption should be met in order to achieve good training results. By the 3rd principle, deeper layers tend to be interleaved layers of nonlinearities and convolutional layers to generate more complex and larger representation of the image."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark**\n",
    "The derivation of a convolutional layer does not fully comply to the definition of *convolution*. Rather, it resembles a *cross-correlation*."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channels\n",
    "\n",
    "Each \"pixel\" tend to be represented by 3 color channels, thus being a vector. Instead of $[X]_{i,j}$, we have $[X]_{i,j,k}$ and $[U]_{i,j,k}$, with an extra index for the multidimension data. The hidden representation can be conceived as convolutional maps being stack together, aka **feature maps**. \n",
    "\n",
    "$$\n",
    "[H]_{i,j,d} = u + \\sum_{a=-\\Delta}^\\Delta\\sum_{b=-\\Delta}^\\Delta\\sum_c[V]_{a,b,c,d}[X]_{i+a,j+b,c}\n",
    "$$\n",
    "\n",
    "Each feature map can be specialized to capture different representations, like edge and textures."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Map & Receptive Field\n",
    "\n",
    "Feature map refers the output of a convolutional layer, while the receptive field refers to any element from the previous layer that has an impact on a single input of this layer."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding\n",
    "\n",
    "The size of a convolutional kernel has an impace on the output matrix, thus the prediction might not have the same shape as the original image. This is undesirable since we intend to say something on the original image. **Padding** is the common solution to manipulate the output dimension.\n",
    "\n",
    "The output dimension is calculated as:\n",
    "$$\n",
    "(n_h-k_h+p_h+1)\\times(n_w-k_w+p_w+1)\n",
    "$$\n",
    "in many cases, we set $p_h=k_h-1$ and $p_w=k_w-1$ to retain the original dimention. For this reason, CNN commonly use kernels with odd height and width values to pad same number of rows and columns around the image."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stride\n",
    "\n",
    "Stride is the number of steps taken by the sliding window function to compute the cross-correlation. Opposite to padding, stride effectively reduces the dimension of the output matrix. It is useful for giant image to save computation power.\n",
    "\n",
    "The output dimension combing both stride and padding is:\n",
    "$$\n",
    "\\lfloor(n_h-k_h+p_h+s_h)/s_h\\rfloor\\times\\lfloor(n_w-k_w+p_w+s_w)/s_w\\rfloor\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Output Channel\n",
    "The actual input may be 3D or more rather than simly 2D. In this case the dimension may be $c_i \\times h_X\\times w_X$, with $c$ being the vector representation of the individual pixel. The convolutional layer can take advantage of the vector representation to output multiple feature maps, thus having dimension of $c_o \\times c_i \\times h_k \\times w_k$. \n",
    "\n",
    "For each single output feature map, the convolution layer is applied to each input channel and linear aggregate the results to one feature map. For multiple-input-output feature map, this process is repeated for $c_o$ times with different parameters. \n",
    "\n",
    "The multiple output channels can be intuitively interpreted as different features."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling \n",
    "\n",
    "Convolutional layers yields coarser representation as it deepens, and can be very sensitive to the locations. To mitigate these effects, pooling is introduced. Pooling similarly uses the idea of sliding window but contains no parameter. Instead, it either computes average or maximum like image downsampling technique. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Realization\n",
    "### Cross-Correlation 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19.]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def corr2d(X, K, stride=(1,1)):\n",
    "    h,w = K.shape\n",
    "    Y = torch.zeros((X.shape[0]-h+stride[0])//stride[0], (X.shape[1]-w+stride[1])//stride[1])\n",
    "    for i in range(0, Y.shape[0]):\n",
    "        for j in range(0, Y.shape[1]):\n",
    "            Y[i,j] = (X[stride[0]*i:h+stride[0]*i, stride[1]*j:stride[1]*j+w] * K).sum()\n",
    "    return Y\n",
    "\n",
    "#Test\n",
    "X = torch.tensor(\n",
    "    [\n",
    "        [0, 1, 2],\n",
    "        [3, 4, 5],\n",
    "        [6, 7, 8]\n",
    "    ]\n",
    ")\n",
    "\n",
    "K = torch.tensor(\n",
    "    [\n",
    "        [0, 1],\n",
    "        [2, 3]\n",
    "    ]\n",
    ")\n",
    "\n",
    "corr2d(X, K, (2,2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-correlation with Multiple Input Channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of 1-output Conv: torch.Size([9, 9])\n",
      "Shape of multiple-output Conv: torch.Size([3, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "# pay attention to the way tensors are ordered\n",
    "\n",
    "def corr2d_multi_in(X, K):\n",
    "    return sum(corr2d(x,k) for x,k in zip(X,K))\n",
    "\n",
    "def corr2d_multi_in_out(X, K):\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K])\n",
    "\n",
    "# Test\n",
    "X = torch.randint(0, 10, (3, 10, 10))\n",
    "K = torch.randint(0, 5, (3, 2, 2))\n",
    "K_mult = torch.randint(0, 5, (3, 3, 2, 2))\n",
    "print(f\"Shape of 1-output Conv: {corr2d_multi_in(X, K).shape}\")\n",
    "print(f\"Shape of multiple-output Conv: {corr2d_multi_in_out(X, K_mult).shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7500, 1.0000, 0.7500, 0.2500, 0.2500, 0.5000, 0.5000, 0.7500, 0.7500],\n",
       "        [1.0000, 1.0000, 0.7500, 0.5000, 0.2500, 0.0000, 0.2500, 0.5000, 0.2500],\n",
       "        [0.7500, 0.5000, 0.2500, 0.2500, 0.5000, 0.2500, 0.2500, 0.5000, 0.2500],\n",
       "        [0.7500, 0.2500, 0.2500, 0.2500, 0.2500, 0.5000, 0.5000, 0.7500, 0.7500],\n",
       "        [1.0000, 0.5000, 0.5000, 0.5000, 0.0000, 0.5000, 0.7500, 0.5000, 0.5000],\n",
       "        [0.7500, 0.7500, 0.5000, 0.5000, 0.2500, 0.2500, 0.7500, 0.5000, 0.2500],\n",
       "        [0.5000, 0.7500, 0.7500, 0.7500, 0.5000, 0.0000, 0.5000, 0.5000, 0.5000],\n",
       "        [0.7500, 0.7500, 1.0000, 0.7500, 0.2500, 0.2500, 0.5000, 0.2500, 0.2500],\n",
       "        [1.0000, 1.0000, 0.7500, 0.5000, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pool2d(X, pool_size, mode='max'):\n",
    "    h,w = pool_size\n",
    "    Y = torch.zeros(X.shape[0]-h+1, X.shape[1]-w+1)\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i,j] = X[i:i+h, j:j+w].max()\n",
    "            else:\n",
    "                Y[i,j] = X[i:i+h, j:j+w].mean()\n",
    "    return Y\n",
    "\n",
    "X = torch.randint(0,2,(10,10), dtype=float)\n",
    "pool2d(X, (2,2), mode='avg')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class Conv2D(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.rand(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return corr2d(x, self.weight) + self.bias"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Naive Edge Detection\n",
    "\n",
    "Let $X$ be an image of an object, we wish to detect the vertical edge of the object. We first manually label the edges and then train a network with only a convolutional layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 1., 1., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 1., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 1., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 1., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 1., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con = Conv2D((1,3))\n",
    "X = torch.tensor([\n",
    "    [0, 1, 1, 1, 0],\n",
    "    [0, 1, 1, 1, 0],\n",
    "    [0, 1, 1, 1, 0],\n",
    "    [0, 1, 1, 1, 0],\n",
    "    [0, 1, 1, 1, 0]\n",
    "])\n",
    "\n",
    "def pad(X, pad_shape):\n",
    "    Y = torch.zeros(X.shape[0] + pad_shape[0] * 2, X.shape[1] + pad_shape[1]*2)\n",
    "    Y[pad_shape[0]:pad_shape[0]+X.shape[0], pad_shape[1]:pad_shape[1]+X.shape[0]] = X\n",
    "    return Y\n",
    "\n",
    "pad(X, (0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y = corr2d(pad(X,(0,1)), torch.tensor([[0,1,0]]))\n",
    "Y = torch.zeros(5,5)\n",
    "Y[:,0] = 1\n",
    "Y[:,-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 19.342042922973633\n",
      "loss: 2.090298652648926\n",
      "loss: 0.9224272966384888\n",
      "loss: 0.5324939489364624\n",
      "loss: 0.33690524101257324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.2512, -1.0569,  0.2512]], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    Y_hat = con(pad(X, (0,1)))\n",
    "    l = (Y_hat - Y)**2\n",
    "    con.zero_grad()\n",
    "    l.sum().backward()\n",
    "    con.weight.data[:] -= 0.01 * con.weight.grad\n",
    "    con.bias.data[:] -= 0.01 * con.bias.grad\n",
    "\n",
    "    if i%10 == 0:\n",
    "        print(f\"loss: {l.sum()}\")\n",
    "con.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.9715, -0.0854,  0.1658, -0.0855,  0.9715],\n",
       "        [ 0.9715, -0.0854,  0.1658, -0.0855,  0.9715],\n",
       "        [ 0.9715, -0.0854,  0.1658, -0.0855,  0.9715],\n",
       "        [ 0.9715, -0.0854,  0.1658, -0.0855,  0.9715],\n",
       "        [ 0.9715, -0.0854,  0.1658, -0.0855,  0.9715]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con(pad(X, (0,1)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 20 rounds of optimization, we observe that the final result is close to what intend to learn."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proof of Concept: LeNet\n",
    "\n",
    "LeNet is a CNN proposed by Le Cunn for digit classification. Here, we implement a CNN similar to the structure of the LeNet and validate its performance on image classifcation task. The benchmark dataset is fashionMNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dl\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "class fashionMNISTLoader(dl.DataModule):\n",
    "    def __init__(self, batch_size=32):\n",
    "        self.save_hyperparameters()\n",
    "        super().__init__()\n",
    "        \n",
    "    def get_dataloader(self, train=True):\n",
    "        if train:\n",
    "            data = torchvision.datasets.FashionMNIST(root='./', train=True, transform=ToTensor())\n",
    "        else:\n",
    "            data = torchvision.datasets.FashionMNIST(root='./', train=False, transform=ToTensor())\n",
    "        self.num_trian = len(data)\n",
    "        loader = torch.utils.data.DataLoader(data, batch_size=self.batch_size)\n",
    "        for X,y in loader:\n",
    "            yield X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(dl.Module):\n",
    "    def __init__(self, eta=0.1, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1,6, kernel_size=5, padding=2), nn.Sigmoid(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(400, 120), nn.Sigmoid(),\n",
    "            nn.Linear(120, 84), nn.Sigmoid(),\n",
    "            nn.Linear(84, num_classes)\n",
    "        )\n",
    "\n",
    "        for each in self.net:\n",
    "            if type(each) == nn.Linear or type(each) == nn.Conv2d:\n",
    "                nn.init.xavier_normal_(each.weight)\n",
    "    \n",
    "\n",
    "    def loss(self, y_hat, y):\n",
    "        return nn.functional.cross_entropy(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = dl.Trainer(max_epochs=10)\n",
    "data = fashionMNISTLoader(batch_size=32)\n",
    "model = LeNet()\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torchvision.datasets.FashionMNIST(root='./', train=False, transform=ToTensor())\n",
    "loader = torch.utils.data.DataLoader(data, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.874\n",
      "0.868\n",
      "0.86\n",
      "0.836\n",
      "0.865\n",
      "0.839\n",
      "0.857\n",
      "0.859\n",
      "0.849\n",
      "0.856\n"
     ]
    }
   ],
   "source": [
    "for X,y in loader:\n",
    "    print(\n",
    "        (model(X).argmax(axis=1) == y).numpy().mean()\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
